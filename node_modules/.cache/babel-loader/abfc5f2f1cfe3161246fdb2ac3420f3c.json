{"ast":null,"code":"import _slicedToArray from \"C:\\\\Users\\\\Rohith\\\\mern\\\\frontend\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/slicedToArray\";\n/**\n * @license\n * Copyright 2022 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '../base';\nimport { Prod } from '../kernel_names';\nimport { cumprod } from '../ops/cumprod';\nimport { mul } from '../ops/mul';\nimport { reshape } from '../ops/reshape';\nimport { transpose } from '../ops/transpose';\n// Gradient for product operation on a single axis.\nfunction prodGradFn_(x, dy, axis) {\n  // The gradient tensor (dy) has a set of axes removed, so we create re-shaped\n  // versions (of size 1) for the removed axis; this supports broadcasting over\n  // those dimensions.\n  var expandedYShape = x.shape.slice();\n  expandedYShape[axis] = 1;\n  // The actual gradient computation.\n  var expandedDy = reshape(dy, expandedYShape);\n  var xCumProd = cumprod(x, axis, true, false);\n  var xCumRevProd = cumprod(x, axis, true, true);\n  var dx = mul(xCumProd, xCumRevProd);\n  return mul(expandedDy, dx);\n}\n// Support gradients when the product is done on many axes at once.\n// This done py pushing all the axes on which the product is applied into a\n// single axis.\nfunction prodsGradFn_(x, dy, axis) {\n  // Move all axes for doing prod over to the end of the tensor.\n  var xRank = x.shape.length;\n  var finalProdAxis = xRank - axis.length;\n  var xPermutation = backend_util.getAxesPermutation(axis, xRank);\n  var permutedX = x;\n  if (xPermutation != null) {\n    permutedX = transpose(x, xPermutation);\n  }\n  // Reshape all the prod dimensions into a single one, and do compute prod\n  // gradients on that.\n  var newShape = permutedX.shape.slice();\n  var removedShape = newShape.splice(xRank - axis.length, axis.length);\n  var endPartShape = removedShape.reduce(function (p, c) {\n    return p * c;\n  }, 1);\n  newShape.push(endPartShape);\n  var reshapedPermutedX = permutedX.reshape(newShape);\n  var prodGrad = prodGradFn_(reshapedPermutedX, dy, finalProdAxis);\n  // Undo the re-shaping now we have the dx vector, and permute back to\n  // original axes order.\n  prodGrad = prodGrad.reshape(permutedX.shape);\n  if (xPermutation != null) {\n    var undoPermutation = backend_util.getUndoAxesPermutation(xPermutation);\n    prodGrad = transpose(prodGrad, undoPermutation);\n  }\n  return prodGrad;\n}\n// Running example:\n// [\n//   [\n//     [3.0, 4.0],\n//     [5.0, 6.0],\n//     [7.0, 8.0]\n//   ],\n//   [\n//     [3.0, 5.0],\n//     [0.0, 6.0],\n//     [5.0, 6.0]\n//   ]\n// ]\n//\nexport var prodGradConfig = {\n  kernelName: Prod,\n  inputsToSave: ['x'],\n  gradFunc: function gradFunc(dy, saved, attrs) {\n    var _saved = _slicedToArray(saved, 1),\n      _x = _saved[0];\n    var axis = attrs.axis;\n    var axisArr = [];\n    if (axis === undefined || axis === null) {\n      axisArr = _x.shape.map(function (_, i) {\n        return i;\n      });\n    } else if (typeof axis === 'number') {\n      axisArr = [axis];\n    } else {\n      axisArr = axis;\n    }\n    return {\n      x: function x() {\n        return prodsGradFn_(_x, dy, axisArr);\n      }\n    };\n  }\n};","map":null,"metadata":{},"sourceType":"module"}